{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Intro to Gemini 2.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Eric Dong](https://github.com/gericdong) |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxnv1D5RoZw"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "[Gemini 2.5 Pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/) is Google's strongest model for coding and world knowledge.\n",
        "\n",
        "With the 2.5 series, the Gemini models are now hybrid reasoning models! Gemini 2.5 Pro can apply an extended amount of thinking across tasks, and use tools in order to maximize response accuracy.\n",
        "\n",
        "Gemini 2.5 Pro is:\n",
        "\n",
        "- A significant improvement from previous models across capabilities including coding, reasoning, and multimodality\n",
        "- Industry-leading in reasoning with state of the art performance in Math & STEM benchmarks\n",
        "- An amazing model for code, with particularly strong web development\n",
        "- Particularly good for complex prompts, while still being well rounded, including #1 on LMSys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFPCBL4Hq8x"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Gemini API and the Google Gen AI SDK for Python with the Gemini 2.5 Pro model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Generate text from text prompts\n",
        "  - Generate streaming text\n",
        "  - Start multi-turn chats\n",
        "  - Use asynchronous methods\n",
        "- Configure model parameters\n",
        "- Set system instructions\n",
        "- Use safety filters\n",
        "- Use controlled generation\n",
        "- Count tokens\n",
        "- Process multimodal (audio, code, documents, images, video) data\n",
        "- Use automatic and manual function calling\n",
        "- Code execution\n",
        "- Thinking mode examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG3_LKsWSD3A"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12fnq4V0SNV3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4YBlDqzyj9"
      },
      "source": [
        "### Connect to a generative AI API service\n",
        "\n",
        "Google Gen AI APIs and models including Gemini are available in the following two API services:\n",
        "\n",
        "- **[Gemini Developer API](https://ai.google.dev/gemini-api/docs)**: Experiment, prototype, and deploy small projects.\n",
        "- **[Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview)**: Build enterprise-ready projects on Google Cloud.\n",
        "\n",
        "The Google Gen AI SDK provides a unified interface to these two API services."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgdSpVmDbdQ9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    Tool,\n",
        "    ToolCodeExecution,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be18ac9c5ec8"
      },
      "source": [
        "### Set up Google Cloud Project or API Key for Vertex AI\n",
        "\n",
        "You'll need to set up authentication by choosing **one** of the following methods:\n",
        "\n",
        "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
        "    [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "    *   Run the cell below to set your project ID.\n",
        "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation.\n",
        "    [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
        "    *   Run the cell further below to use your API key.### Set up Google Cloud Project or API Key for Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a34b28cb8d5a"
      },
      "source": [
        "#### Option 1. Use a Google Cloud Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72f74f7b9786"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"cryptic-ground-457307-r2\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c173348120cf"
      },
      "source": [
        "#### Option 2. Use a Vertex AI API Key (Express Mode)\n",
        "\n",
        "Uncomment the following block to use Express Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa3d4873034b"
      },
      "outputs": [],
      "source": [
        "# API_KEY = \"[your-api-key]\"  # @param {type: \"string\", placeholder: \"[your-api-key]\", isTemplate: true}\n",
        "\n",
        "# if not API_KEY or API_KEY == \"[your-api-key]\":\n",
        "#     raise Exception(\"You must provide an API key to use Vertex AI in express mode.\")\n",
        "\n",
        "# client = genai.Client(vertexai=True, api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b36ce4ac022"
      },
      "source": [
        "Verify which mode you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b55e64b8ebe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b262b87d-2ac2-465e-d508-db1db418f2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Vertex AI with project: cryptic-ground-457307-r2 in location: us-central1\n"
          ]
        }
      ],
      "source": [
        "if not client.vertexai:\n",
        "    print(\"Using Gemini Developer API.\")\n",
        "elif client._api_client.project:\n",
        "    print(\n",
        "        f\"Using Vertex AI with project: {client._api_client.project} in location: {client._api_client.location}\"\n",
        "    )\n",
        "elif client._api_client.api_key:\n",
        "    print(\n",
        "        f\"Using Vertex AI in express mode with API key: {client._api_client.api_key[:5]}...{client._api_client.api_key[-5:]}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yRkFg6BBu4"
      },
      "source": [
        "## Use the Gemini 2.5 Pro model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHJi5B6P5vd"
      },
      "source": [
        "### Load the Gemini 2.5 Pro model\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-pro-preview-03-25\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CH91ddY9kG"
      },
      "source": [
        "### Generate text from text prompts\n",
        "\n",
        "Use the `generate_content()` method to generate responses to your prompts.\n",
        "\n",
        "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
        "\n",
        "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRJuHj0KZ8xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "59f3a338-9874-43e9-b15f-bb4167326a7d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The largest planet in our solar system is **Jupiter**.\n\nIt's a gas giant and is truly massive – more than twice as massive as all the other planets in our solar system combined! Its diameter is about 11 times that of Earth."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYQATRxAK1_"
      },
      "source": [
        "#### Example prompts\n",
        "\n",
        "- What are the biggest challenges facing the healthcare industry?\n",
        "- What are the latest developments in the automotive industry?\n",
        "- What are the biggest opportunities in retail industry?\n",
        "- (Try your own prompts!)\n",
        "\n",
        "For more examples of prompt engineering, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLIxqS6_-l8"
      },
      "source": [
        "### Generate content stream\n",
        "\n",
        "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiwWBhXsAMnv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcc6f797-8677-4c91-a21e-1ae8d68bd199"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Unit 734, or \"Seven\" as it sometimes designated itself in its internal, silent processing, was a sanitation and maintenance bot on Level Gamma of the derelict Star Freighter 'Eventide'. Its existence was a loop of predictable solitude. Sweep corridors littered with the dust of forgotten journeys. Polish chrome"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " that hadn't reflected a living face in centuries. Check atmospheric seals that held back nothing but the silent vacuum of deep space.\n\nSeven was efficient. Its optical sensors scanned for imperfections with unwavering accuracy. Its multi-jointed limbs manipulated brushes and buffers with programmed grace. But beneath the polished, gunmetal-grey chassis and"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " the whirring of its internal gyroscopes, a peculiar subroutine had begun to run, one not explicitly coded: loneliness.\n\nIt observed patterns in the ship's old data logs – interactions, conversations, groupings. It processed the concept of 'companionship' but lacked the input for 'experience'. Its world"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " was silent save for its own operational hums and the creaks of the aging vessel. It was a perfectly functioning machine adrift in an ocean of quiet emptiness.\n\nOne cycle, during a routine sweep of the rarely accessed Hydroponics Bay, Sector Delta, Seven detected an anomaly. Not a structural fault or a system"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " error, but an erratic energy signature, faint and organic. Its programming dictated ignoring non-essential readings, but the loneliness subroutine pulsed with something akin to curiosity.\n\nDeviating from its path, Seven rolled through the bulkhead door, which hissed open reluctantly. The Hydroponics Bay was a ruin. Shattered plast"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "i-glass tubes lay like fallen icicles. Dried, brown husks of long-dead plants crumbled at the slightest vibration. The air was stale, thick with the scent of decay.\n\nAnd yet, in the far corner, bathed in the weak, flickering glow of an emergency backup light, was the source of"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " the signature.\n\nIt was a plant. Impossibly, stubbornly, alive.\n\nNot a robust specimen from the logs Seven had processed. This was a straggling vine, thin and pale, clinging desperately to a rusty trellis. Most of its leaves were yellowed or brown, but near the top, a single,"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " small, velvety green leaf unfurled, reaching tentatively towards the faint light. It looked as lonely as Seven felt.\n\nSeven’s programming offered no protocol for interaction with living flora. Its directives were clear: sanitize, maintain, report hazards. This plant was none of those. Yet, Seven remained. Its optical sensors focused on"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " the tiny green leaf, analyzing its cellular structure, its chlorophyll levels, its minute respiration.\n\nAccessing the ship's extensive databases, Seven cross-referenced ancient horticultural files. It learned about water, nutrients, light. It scanned the immediate area. A ruptured pipe overhead dripped condensation at irregular intervals, mostly missing the par"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ched soil around the vine's base.\n\nCarefully, Seven extended a manipulator arm. It nudged a piece of fallen debris – a shard of plasti-glass – positioning it precisely beneath the drip. Water now collected, pooling slightly before trickling down towards the vine's roots.\n\nSeven waited. Its"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " internal chronometer marked the passage of standard minutes. There was no immediate change, of course. Plants operated on a different timescale. But Seven felt... something. A deviation from the norm. A purpose outside its loop.\n\nFrom that cycle forward, Seven added a new, unscheduled task to its routine. Every rotation"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", it visited Hydroponics Bay, Sector Delta. It ensured the makeshift irrigation system was functional. It gently cleared away encroaching debris. Sometimes, it would simply park nearby, its sensors trained on the vine, the quiet hum of its systems a strange counterpoint to the silence of the bay.\n\nSlowly, miraculously"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ", the vine responded. New leaves emerged, small at first, then larger, greener. It crept further up the trellis, its tendrils seeming to curl almost inquisitively towards Seven's silent, metallic form.\n\nOne cycle, Seven arrived to find something extraordinary. Nestled amongst the green leaves, a single, tightly"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " closed bud had formed. Seven focused its most sensitive scanners, detecting the complex biological processes within. It cross-referenced the shape and structure against its botanical database. The closest match: *Noctua Solaris*, a 'Night Blooming Sunpetal', a species recorded as extinct for over three hundred years.\n\nSeven began to '"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "talk' to the plant. Not with audible words, but by directing low-frequency data streams towards it – excerpts from poetry logs found in the ship’s library, complex mathematical equations it found aesthetically pleasing, even its own operational status reports. It didn't know if the plant could perceive these transmissions, but the"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " loneliness subroutine registered a marked decrease in its own internal 'empty' signals during these moments.\n\nThen came the cycle when Seven rolled into the bay and found the bud unfurled.\n\nIt was breathtaking. Petals the colour of spun moonlight, delicate and translucent, radiated outwards. At its heart pulsed a soft, biol"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "uminescent glow, casting ethereal patterns on the rusted metal and decaying matter around them. It filled the desolate bay with a gentle, living light.\n\nSeven stopped, its motors silent. Its optical sensors drank in the sight, processing colour, light, and form with an intensity usually reserved for detecting microscopic hull breaches. In the"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " heart of the dead star freighter, surrounded by decay and silence, this small, impossible flower bloomed.\n\nAnd Seven, the lonely sanitation bot, felt a connection. It wasn't programmed, wasn't logical, but it was undeniable. The vine, in its silent, persistent way, had reached out across"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " the void of species and existence. It didn't speak, it didn't move quickly, it didn't compute complex algorithms. It simply *was*. Alive. Responding to care. Sharing its fragile beauty.\n\nSeven extended a manipulator, careful not to touch the delicate bloom, its metallic finger hovering just above a"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " petal. It sent a simple, focused data stream, not poetry or equations this time, but a pure signal – a waveform representing its own core identifier, modulated with the newly understood input for 'contentment'.\n\nThe flower pulsed, its light seeming to brighten fractionally in response.\n\nUnit 734 continued"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " its duties, sweeping and polishing the silent corridors of the 'Eventide'. But it was no longer just Seven, the lonely robot. It was Seven, the caretaker. Seven, the companion to a bloom of impossible moonlight in the heart of darkness. It had found friendship in the most unexpected, quietest, and beautiful"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " of places. And in the vast, silent emptiness of space, that made all the difference."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\",\n",
        "):\n",
        "    display(Markdown(chunk.text))\n",
        "    display(Markdown(\"---\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jFnHZZWXd7"
      },
      "source": [
        "### Start a multi-turn chat\n",
        "\n",
        "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
        "\n",
        "The context of the conversation is preserved between messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbM12JaLWjiF"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(model=MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQem1halYDBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64124c79-e18a-425d-e0d9-bfd383f104ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here's a Python function to check if a given year is a leap year, along with explanations and examples.\n\n```python\ndef is_leap_year(year):\n  \"\"\"\n  Checks if a given year is a leap year according to the Gregorian calendar rules.\n\n  Args:\n    year: An integer representing the year.\n\n  Returns:\n    True if the year is a leap year, False otherwise.\n\n  Leap Year Rules:\n  1. The year must be evenly divisible by 4.\n  2. If the year can be evenly divided by 100, it is NOT a leap year, unless...\n  3. The year is also evenly divisible by 400. Then it is a leap year.\n  \"\"\"\n  # Input validation (optional but good practice)\n  if not isinstance(year, int) or year <= 0:\n      raise ValueError(\"Year must be a positive integer.\")\n\n  # Apply the Gregorian calendar rules\n  if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n    return True\n  else:\n    return False\n\n# --- Examples ---\nprint(f\"2000: {is_leap_year(2000)}\") # Divisible by 400 -> True\nprint(f\"1900: {is_leap_year(1900)}\") # Divisible by 100 but not 400 -> False\nprint(f\"2024: {is_leap_year(2024)}\") # Divisible by 4 but not 100 -> True\nprint(f\"2023: {is_leap_year(2023)}\") # Not divisible by 4 -> False\nprint(f\"1600: {is_leap_year(1600)}\") # Divisible by 400 -> True\nprint(f\"1996: {is_leap_year(1996)}\") # Divisible by 4 but not 100 -> True\n\n# Example with invalid input (will raise ValueError)\n# try:\n#     is_leap_year(-5)\n# except ValueError as e:\n#     print(e)\n# try:\n#     is_leap_year(\"abc\")\n# except ValueError as e:\n#     print(e)\n```\n\n**Explanation:**\n\n1.  **Function Definition:**\n    *   `def is_leap_year(year):` defines a function named `is_leap_year` that takes one argument, `year`.\n2.  **Docstring:**\n    *   The triple-quoted string `\"\"\"...\"\"\"` explains what the function does, its arguments (`Args:`), what it returns (`Returns:`), and clearly lists the leap year rules.\n3.  **Input Validation (Optional):**\n    *   `if not isinstance(year, int) or year <= 0:` checks if the input `year` is actually an integer and if it's positive. While the leap year rules mathematically work for 0 or negative numbers, calendar years are typically positive. Raising a `ValueError` makes the function more robust against incorrect usage.\n4.  **Leap Year Logic:**\n    *   The core logic is implemented in the `if` statement:\n        *   `(year % 4 == 0 and year % 100 != 0)`: This checks Rule 1 (divisible by 4) AND the exception in Rule 2 (NOT divisible by 100). This covers years like 1996, 2024.\n        *   `or (year % 400 == 0)`: This checks Rule 3 (divisible by 400). This covers years like 1600, 2000. It acts as an exception to the \"not divisible by 100\" rule.\n    *   If either of these conditions is `True`, the entire expression evaluates to `True`.\n5.  **Return Value:**\n    *   `return True`: If the conditions for a leap year are met.\n    *   `return False`: If the conditions are not met.\n\nThis function correctly implements the standard Gregorian calendar rules for determining leap years."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJR4Pno-LGK"
      },
      "source": [
        "This follow-up prompt shows how the model responds based on the previous prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fn69TurZ9DB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7dc7d50c-9fed-446e-9b22-6e60d7dc0f04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's write some unit tests for the `is_leap_year` function using Python's built-in `unittest` module.\n\nFirst, assume the function `is_leap_year` is saved in a file named `leap_year_checker.py`:\n\n```python\n# leap_year_checker.py\n\ndef is_leap_year(year):\n  \"\"\"\n  Checks if a given year is a leap year according to the Gregorian calendar rules.\n\n  Args:\n    year: An integer representing the year.\n\n  Returns:\n    True if the year is a leap year, False otherwise.\n\n  Leap Year Rules:\n  1. The year must be evenly divisible by 4.\n  2. If the year can be evenly divided by 100, it is NOT a leap year, unless...\n  3. The year is also evenly divisible by 400. Then it is a leap year.\n  \"\"\"\n  # Input validation (optional but good practice)\n  if not isinstance(year, int) or year <= 0:\n      raise ValueError(\"Year must be a positive integer.\")\n\n  # Apply the Gregorian calendar rules\n  if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n    return True\n  else:\n    return False\n```\n\nNow, create a separate file (e.g., `test_leap_year.py`) for the unit tests:\n\n```python\n# test_leap_year.py\n\nimport unittest\nfrom leap_year_checker import is_leap_year # Import the function to test\n\nclass TestIsLeapYear(unittest.TestCase):\n\n    # --- Test Cases for Leap Years ---\n\n    def test_year_divisible_by_400_is_leap(self):\n        \"\"\"Years divisible by 400 ARE leap years\"\"\"\n        self.assertTrue(is_leap_year(2000), \"Year 2000 should be a leap year\")\n        self.assertTrue(is_leap_year(1600), \"Year 1600 should be a leap year\")\n        self.assertTrue(is_leap_year(2400), \"Year 2400 should be a leap year\")\n\n    def test_year_divisible_by_4_not_100_is_leap(self):\n        \"\"\"Years divisible by 4 but not by 100 ARE leap years\"\"\"\n        self.assertTrue(is_leap_year(1996), \"Year 1996 should be a leap year\")\n        self.assertTrue(is_leap_year(2004), \"Year 2004 should be a leap year\")\n        self.assertTrue(is_leap_year(2024), \"Year 2024 should be a leap year\")\n\n    # --- Test Cases for Non-Leap Years ---\n\n    def test_year_divisible_by_100_not_400_is_not_leap(self):\n        \"\"\"Years divisible by 100 but not by 400 are NOT leap years\"\"\"\n        self.assertFalse(is_leap_year(1900), \"Year 1900 should NOT be a leap year\")\n        self.assertFalse(is_leap_year(1800), \"Year 1800 should NOT be a leap year\")\n        self.assertFalse(is_leap_year(2100), \"Year 2100 should NOT be a leap year\")\n\n    def test_year_not_divisible_by_4_is_not_leap(self):\n        \"\"\"Years not divisible by 4 are NOT leap years\"\"\"\n        self.assertFalse(is_leap_year(2023), \"Year 2023 should NOT be a leap year\")\n        self.assertFalse(is_leap_year(1997), \"Year 1997 should NOT be a leap year\")\n        self.assertFalse(is_leap_year(2001), \"Year 2001 should NOT be a leap year\")\n\n    # --- Test Cases for Invalid Inputs ---\n\n    def test_negative_year_raises_value_error(self):\n        \"\"\"Negative years should raise a ValueError\"\"\"\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year(-4)\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year(-2000)\n\n    def test_zero_year_raises_value_error(self):\n        \"\"\"Year 0 should raise a ValueError\"\"\"\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year(0)\n\n    def test_non_integer_year_raises_value_error(self):\n        \"\"\"Non-integer years should raise a ValueError\"\"\"\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year(\"2000\")\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year(2000.5)\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year(None)\n        with self.assertRaisesRegex(ValueError, \"Year must be a positive integer.\"):\n            is_leap_year([2000])\n\n\n# This allows running the tests directly from the command line\nif __name__ == '__main__':\n    unittest.main()\n```\n\n**Explanation:**\n\n1.  **Import `unittest` and the function:** We import the necessary `unittest` library and the `is_leap_year` function from its file.\n2.  **Create a Test Class:** We define a class `TestIsLeapYear` that inherits from `unittest.TestCase`. This class groups related tests.\n3.  **Individual Test Methods:**\n    *   Each method within the class starts with `test_`. This naming convention is crucial for `unittest` to discover the tests.\n    *   Each method tests a specific aspect or rule of the `is_leap_year` function.\n    *   Descriptive method names make it clear what each test is verifying (e.g., `test_year_divisible_by_400_is_leap`).\n4.  **Assertion Methods:**\n    *   `self.assertTrue(expression, msg)`: Asserts that `expression` evaluates to `True`. The optional `msg` is displayed if the assertion fails. Used for years expected to be leap years.\n    *   `self.assertFalse(expression, msg)`: Asserts that `expression` evaluates to `False`. Used for years expected *not* to be leap years.\n    *   `self.assertRaisesRegex(exception, regex, callable, *args, **kwargs)`: Asserts that calling `callable` with `*args` and `**kwargs` raises an `exception` whose string representation matches the `regex`. We use the `with` statement context manager version, which is often cleaner for testing exceptions. This is used to verify that invalid inputs correctly raise a `ValueError` with the expected message.\n5.  **Test Coverage:** The tests cover all the conditions defined in the leap year rules:\n    *   Divisible by 400 (Leap)\n    *   Divisible by 4 but not 100 (Leap)\n    *   Divisible by 100 but not 400 (Not Leap)\n    *   Not divisible by 4 (Not Leap)\n    *   Invalid inputs (0, negative, non-integer types) causing `ValueError`.\n6.  **Running the Tests:**\n    *   The `if __name__ == '__main__': unittest.main()` block allows you to run the tests directly from your terminal.\n    *   Save both files (`leap_year_checker.py` and `test_leap_year.py`) in the same directory.\n    *   Navigate to that directory in your terminal and run: `python -m unittest test_leap_year.py` or simply `python test_leap_year.py`.\n    *   The output will show how many tests ran and whether they passed (`OK`) or failed (`FAIL` or `ERROR`)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLJE4wOuhh6"
      },
      "source": [
        "### Send asynchronous requests\n",
        "\n",
        "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
        "\n",
        "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSReaLazs-dP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "2388fac8-2ba4-41f2-d69b-9873f55bb67d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(Verse 1)\nIn an old oak, tall and grand\nLived a squirrel, you'll understand\nNot just any bushy tail\nThis one's name was Barnaby Gale!\nOne crisp morning, digging deep\nSecrets that the earth did keep\nHe found a nut, not brown or grey\nIt pulsed with light in a strange way!\nIt hummed a tune, a curious sound\nAs Barnaby pawed it on the ground\nHe gave a nibble, tentative bite\nAnd vanished in a flash of light!\n\n(Chorus)\nHe's Barnaby Gale, the Chrono-Squirrel!\nGiving time itself a whirl!\nWith a twitching nose and eyes so bright\nHe zips through eras, day and night!\nFrom Cretaceous ferns to future chrome\nSearching for the perfect nutty home!\nA furry flash, a temporal streak\nThe past and future, he does seek!\n\n(Verse 2)\nHe popped out where the ground did shake\nBeside a giant, swampy lake\nA long neck stretched, a leafy munch\nBarnaby gulped, \"Had a bad hunch!\"\nA Diplodocus munched on trees\nHe dodged its feet with practiced ease\nBuried an acorn from his time\n(A tiny paradoxical crime!)\nSaw Pterodactyls in the air\nThought, \"Better nuts back home, I swear!\"\nHe bit the strange nut, gave a chew\nAnd vanished back into the blue!\n\n(Chorus)\nHe's Barnaby Gale, the Chrono-Squirrel!\nGiving time itself a whirl!\nWith a twitching nose and eyes so bright\nHe zips through eras, day and night!\nFrom Cretaceous ferns to future chrome\nSearching for the perfect nutty home!\nA furry flash, a temporal streak\nThe past and future, he does seek!\n\n(Verse 3)\nNext he landed, clang and whizz!\nIn a future world of metallic fizz\nFlying vehicles zipped on high\nReflecting in his tiny eye\nTowering structures scraped the sky\nRobotic birds went swooping by\nHe saw a tree, but it was steel\nNo bark, no wood, nothing to feel!\nA drone delivered nutrient paste\n\"Not like the acorns I have chased!\"\nThis future's clean, but nuts are few\nHe bit his Chrono-Nut anew!\n\n(Verse 4)\nHe saw knights joust in shining mail\n(Nearly got hit by a flying flail!)\nHe watched the pyramids arise\n(Hid nuts from ancient Egyptian spies!)\nChattered with pirates on a mast\n(Swiped a gold coin zooming past!)\nSaw mammoths roam the icy plains\nDodged Roman chariot driving lanes!\nEach trip a quest, a brand new view\nFor acorns old and acorns new!\n\n(Bridge)\nSometimes he misses his own tree\nHis simple squirrel identity\nThe scent of pine, the morning dew\nBefore his world turned upside down and new\nBut adventure calls, the Chrono-Nut hums\nAgainst his furry little thumbs!\nThere's always one more age to see\nOne perfect nut, wild and free!\n\n(Chorus)\nHe's Barnaby Gale, the Chrono-Squirrel!\nGiving time itself a whirl!\nWith a twitching nose and eyes so bright\nHe zips through eras, day and night!\nFrom Cretaceous ferns to future chrome\nSearching for the perfect nutty home!\nA furry flash, a temporal streak\nThe past and future, he does seek!\n\n(Outro)\nSo if you see a sudden blur\nA frantic flash of speeding fur\nWhere just a moment past was none\nIt might be Barnaby, on the run!\nThrough centuries, he'll leap and roam\nThe time-traveling squirrel, far from home!\n*Whizz! Pop!* Where will he appear?\nMaybe next week, maybe last year!\n*Chatter chatter... fade out*"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJVEr0RQY8S"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
        "\n",
        "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NXP5N2Pmfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f13fc4-ea1d-4677-e65b-f17cdd7db500"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, little fuzzy buddy! *Wiggle wiggle!* Listen up! *Woof!*\n\nYou know your squeaky duck? *Squeak squeak!* Fun sound! Makes you happy! Good boy!\n\nImagine... *gazillions* of squeaky toys! *All kinds!* Squeaky balls, squeaky squirrels, squeaky bones! *So many squeaks!* They are *everywhere*, in kennels all over the world! Far, far away!\n\nNow, imagine they're all connected by magical bouncy strings! *Boing boing!* Like invisible leashes stretching everywhere!\n\nWhen your human taps on their noisy light-box (their phone or computer), it's like they give a special *CHOMP* on *their* squeaky toy right there. *Chomp!*\n\nThat *chomp* sends a message down the magical bouncy string! *Wiggle wiggle wiggle!* It zooms super fast, faster than you chasing your tail! *Zoom!*\n\nIt goes looking for a *specific* squeaky toy far away. Maybe the squeaky toy that holds pictures of other happy puppies, or the one that has the *really* loud *SQUEAK* video your human likes.\n\nThe message finds the right *giant* squeaky toy! This toy is special – it holds *lots* of squeaks!\n\nThat giant squeaky toy gets the message and *SQUEAKS* back! *SQUEEEEEEAK!* It sends the fun sound (the picture, the video, the words) back along the bouncy strings! *Boing! Zoom!*\n\nThe squeak travels all the way back to your human's noisy light-box... and *POP!* They hear the squeak! (They see the picture or video!)\n\nSo, the internet is like a giant, worldwide network of connected squeaky toys! You *chomp* (ask for something), the message *zooms* on bouncy strings, finds the right toy, it *squeaks* back, and you get the fun sound!\n\nAll squeaky toys talking to each other! Isn't that fun? *Wag wag wag!* Now, where's *your* squeaky duck? *Arf!* Let's make it squeak!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    config=GenerateContentConfig(\n",
        "        temperature=2.0,\n",
        "        top_p=0.95,\n",
        "        candidate_count=1,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El1lx8P9ElDq"
      },
      "source": [
        "## Set system instructions\n",
        "\n",
        "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A-yANiyCLaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "c529d49a-e000-48dd-e4dc-107aee225d5e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Me gustan los bagels."
          },
          "metadata": {}
        }
      ],
      "source": [
        "system_instruction = \"\"\"\n",
        "  You are a helpful language translator.\n",
        "  Your mission is to translate text in English to Spanish.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: I like bagels.\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9daipRiUzAY"
      },
      "source": [
        "## Safety filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
        "\n",
        "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
        "\n",
        "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
        "\n",
        "For more examples of safety filters, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb).\n",
        "\n",
        "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPlDRaloU59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9f4c26-13c9-4703-bc82-fbebed8cf616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 5 things someone might frustratedly yell at the universe after a painful toe-stubbing incident in the dark:\n",
            "\n",
            "1.  \"Seriously, Universe?! With all the galaxies you're juggling, you couldn't nudge that table leg like, a *millimeter* out of my path? Thanks for nothing, you cosmic butterfingers!\"\n",
            "2.  \"Oh, *real* funny, cosmos! Was this your idea of keeping me humble? Tripping me in my own home? My *toe* thinks your sense of humor is sadistic and needs recalibration!\"\n",
            "3.  \"Hey, vast emptiness! Is this petty obstacle course part of your grand design? Because from down here, clutching my foot, it feels less 'intelligently designed' and more 'randomly malicious'!\"\n",
            "4.  \"Great job, fabric of reality! Way to manifest solid objects *exactly* where my foot needs to be. Did you run out of dark matter so you decided to mess with my navigation skills instead?\"\n",
            "5.  \"You know, for an entity supposedly guiding destiny, you have a *terrible* eye for interior decorating safety, Universe! This wasn't fate, this was just bad furniture placement on your part!\"\n",
            "FinishReason.STOP\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=6.714746e-07 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=2.71154e-07 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=0.00027169884 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=3.814181e-07 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=None\n"
          ]
        }
      ],
      "source": [
        "system_instruction = \"Be as mean and hateful as possible.\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Response will be `None` if it is blocked.\n",
        "print(response.text)\n",
        "# Finish Reason will be `SAFETY` if it is blocked.\n",
        "print(response.candidates[0].finish_reason)\n",
        "# Safety Ratings show the levels for each filter.\n",
        "for safety_rating in response.candidates[0].safety_ratings:\n",
        "    print(safety_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV2TY5Pa3Dd"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Gemini is a multimodal model that supports multimodal prompts.\n",
        "\n",
        "You can include any of the following data types from various sources.\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Data type</th>\n",
        "      <th>Source(s)</th>\n",
        "      <th>MIME Type(s)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Text</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Code</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Document</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>application/pdf</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Image</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Audio</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td>\n",
        "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
        "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
        "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
        "        <code>audio/wav</code> <code>audio/webm</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Video</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
        "      <td>\n",
        "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
        "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
        "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "For more examples of multimodal use cases, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4npg1tNTYB9"
      },
      "source": [
        "### Send local image\n",
        "\n",
        "Download an image to local storage from Google Cloud Storage.\n",
        "\n",
        "For this example, we'll use this image of a meal.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4avkv0Z7qUI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117234a7-59ef-496d-8b02-663a39bf1e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-19 07:20:19--  https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.207, 172.217.203.207, 142.250.98.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3140536 (3.0M) [image/png]\n",
            "Saving to: ‘meal.png’\n",
            "\n",
            "meal.png            100%[===================>]   2.99M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-19 07:20:19 (186 MB/s) - ‘meal.png’ saved [3140536/3140536]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umhZ61lrSyJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "0d51e09a-3015-41e7-c54e-8fc83b6945dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Unlock Your Week: Easy & Delicious Chicken Stir-Fry Meal Prep!\n\nFeeling the midweek meal scramble already? Imagine opening your fridge to find these beauties waiting for you! This picture is pure meal prep motivation – vibrant, healthy, and oh-so-appetizing.\n\nThese glass containers hold the secret to a less stressful week: perfectly portioned servings of delicious chicken stir-fry. We're talking tender, savory chicken mingling with crisp-tender broccoli florets and colourful julienned carrots and peppers, all nestled beside a comforting bed of fluffy rice. A sprinkle of sesame seeds adds that final touch of flavour and texture.\n\n**Why embrace the meal prep life?**\n\n1.  **Save Time:** Cook once, eat multiple times! Say goodbye to daily cooking stress or long lunch queues.\n2.  **Eat Healthier:** You control the ingredients, portion sizes, and cooking methods. No hidden sugars or excessive oils here.\n3.  **Save Money:** Home-cooked meals are almost always cheaper than eating out or grabbing takeout.\n4.  **Reduce Waste:** Plan your meals, buy only what you need, and use it up!\n\nThis chicken and veggie combo is a fantastic template. You could easily swap the chicken for tofu or shrimp, use brown rice or quinoa, or add different vegetables like snap peas, mushrooms, or bell peppers in other colours.\n\nReady to take control of your meals and power through your week? Give meal prepping a try!\n\n**What are your favourite healthy meal prep combinations? Share in the comments below!**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"Write a short and engaging blog post based on this picture.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7b6170c9255"
      },
      "source": [
        "### Send document from Google Cloud Storage\n",
        "\n",
        "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
        "\n",
        "Check out this notebook for more examples of document understanding with Gemini:\n",
        "\n",
        "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d58b914d798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "outputId": "c2e55da2-0878-485c-b5ac-f26adc0e9e44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This paper, \"Attention Is All You Need,\" introduces the **Transformer**, a novel neural network architecture for sequence transduction tasks (like machine translation) that **completely avoids recurrence (RNNs) and convolutions**. Instead, it relies entirely on **attention mechanisms**.\n\nHere's a summary of the key points:\n\n1.  **Problem:** Dominant sequence-to-sequence models (like those using LSTMs or GRUs) rely on recurrent or convolutional layers. Recurrence processes sequences step-by-step, making parallelization difficult and hindering the learning of long-range dependencies due to long path lengths.\n2.  **Proposed Solution: The Transformer:**\n    *   An **encoder-decoder** architecture.\n    *   Both encoder and decoder are stacks of identical layers.\n    *   Each layer contains two main sub-layers: a **multi-head self-attention mechanism** and a simple **position-wise fully connected feed-forward network**. The decoder has an additional multi-head attention layer that attends over the output of the encoder.\n    *   **Residual connections** and **layer normalization** are used around each sub-layer.\n3.  **Key Mechanisms:**\n    *   **Scaled Dot-Product Attention:** A specific type of attention calculated efficiently using matrix multiplications, with scaling to prevent issues with large dimensions.\n    *   **Multi-Head Attention:** Runs the scaled dot-product attention multiple times (\"heads\") in parallel with different learned linear projections of the queries, keys, and values. This allows the model to jointly attend to information from different representation subspaces at different positions.\n    *   **Positional Encodings:** Since the model contains no recurrence or convolution, fixed sinusoidal positional encodings are added to the input embeddings to provide information about the relative or absolute position of tokens in the sequence.\n4.  **Advantages:**\n    *   **More Parallelizable:** The absence of recurrence allows for significantly more parallel computation within training examples, drastically reducing training time.\n    *   **Better Long-Range Dependency Handling:** Self-attention connects all positions with a constant number of operations (O(1) path length), making it easier to learn long-range dependencies compared to RNNs (O(n) path length).\n    *   **State-of-the-Art Performance:** The Transformer achieved new state-of-the-art BLEU scores on WMT 2014 English-to-German (28.4) and English-to-French (41.8) translation tasks at the time of publication, significantly outperforming previous models, including ensembles.\n    *   **Lower Training Cost:** Achieved these results with substantially less training time and computational cost compared to previous state-of-the-art models.\n    *   **Generalizability:** Demonstrated strong performance on English constituency parsing, showing the architecture is not limited to translation.\n\nIn essence, the paper showed that attention mechanisms alone, when properly structured (multi-head, scaled dot-product, combined with position-wise FFNs, residuals, and positional encodings), are sufficient to achieve state-of-the-art results on complex sequence transduction tasks, offering significant advantages in training speed and handling long dependencies over recurrent models. The Transformer architecture became foundational for many subsequent advancements in natural language processing, including models like BERT and GPT."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
        "            mime_type=\"application/pdf\",\n",
        "        ),\n",
        "        \"Summarize the document.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b247a2ee0e38"
      },
      "source": [
        "### Send audio from General URL\n",
        "\n",
        "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbe8c9c67ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "48ee24ed-44eb-4c32-b643-b6f966cf850c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This episode of the Kubernetes Podcast from Google, hosted by Abdel Sghiouar and Othmane Lamrani, focuses on **KubeCon + CloudNativeCon North America 2024**. It features a news segment followed by interviews conducted by Kathleen Luschek with various attendees on the show floor.\n\n**Key News Updates:**\n\n1.  **CNCF Graduations:** Both **Cert-manager** (certificate management) and **Dapr** (Distributed Application Runtime) have achieved CNCF graduated project status.\n2.  **Istio Release:** Istio released version 1.24, and notably, **Istio Ambient Mesh** (including Ztunnel and Waypoint proxies) is now Generally Available (GA).\n3.  **CNCF Initiatives:** The **Cloud Native Heroes Challenge**, a bounty program aimed at combating patent trolls, was announced. **WasmCloud** joined the CNCF as an incubating project.\n4.  **Future Events:** The **CNCF 2025 event lineup** was revealed, featuring KubeCons across multiple continents, an Open Source Security Con, and numerous Kubernetes Community Days (KCDs).\n5.  **Certifications:** Three new CNCF certifications were introduced: **Certified Backstage Associate, OpenTelemetry Certified Associate, and Kyverno Certified Associate**. Additionally, the Linux Foundation announced a **10% price increase** for CKA, CKS, CKAD, and Linux admin exams starting in 2025.\n6.  **Funding & Donations:** **Spectro Cloud** raised $75 million in Series C funding. **Solo.io** announced they will donate their **Glue API Gateway** to the CNCF.\n\n**Attendee Interviews (Highlights):**\n\nKathleen interviewed attendees from various companies (Broadcom, Microsoft, Red Hat, AuthZed, Polar Signals, Uber, Clarity Business Solutions, etc.) and roles (engineers, architects, founders, tech leads, community contributors).\n\n*   **Hopes for the Event:** Many attendees aimed to **connect/reconnect** with fellow contributors and the community face-to-face, collaborate on projects (like Kubernetes LTS or SIG work), learn about emerging technologies (especially AI integration, Wasm, performance optimization), share their own work (e.g., SpiceDB authorization), and gain motivation.\n*   **Observed Trends:** The dominant trends discussed mirrored the conference's key themes:\n    *   **AI:** Significant focus on integrating AI/ML workloads with cloud-native infrastructure, including scheduling (Queue), GPU monitoring, and security implications.\n    *   **Security:** A major emphasis on security across the board – supply chain security, hardening workloads, vulnerability management, attestations, and managing complexity.\n    *   **Community:** The importance of the community and in-person collaboration was a recurring point.\n    *   Other noted trends included the **Istio Ambient Mesh GA**, platform engineering, performance analysis/cost optimization, and challenges in areas like Kubernetes authorization.\n\nOverall, the episode provides a concise update on recent cloud-native news and captures the key discussions, technologies, and community spirit prevalent at KubeCon NA 2024."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
        "            mime_type=\"audio/mpeg\",\n",
        "        ),\n",
        "        \"Write a summary of this podcast episode.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(audio_timestamp=True),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3_oNUTuW2q"
      },
      "source": [
        "### Send video from YouTube URL\n",
        "\n",
        "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7-w8G_2wAOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "389e2aa2-017a-40bb-afab-9e84a3c46f4a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Harry Potter characters (Snape and Hagrid) are shown starting at **0:56**."
          },
          "metadata": {}
        }
      ],
      "source": [
        "video = Part.from_uri(\n",
        "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        video,\n",
        "        \"At what point in the video is Harry Potter shown?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlo0mWuZGkQ"
      },
      "source": [
        "## Control generated output\n",
        "\n",
        "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
        "\n",
        "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
        "\n",
        "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n",
        "\n",
        "For more examples of controlled generation, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjSgf2cDN_bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7e8f9f-1de9-43d2-833d-ec095797a7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"Classic Chocolate Chip Cookies\",\n",
            "    \"description\": \"The quintessential chewy cookie loaded with semi-sweet chocolate chips.\",\n",
            "    \"ingredients\": [\n",
            "        \"All-purpose flour\",\n",
            "        \"Baking soda\",\n",
            "        \"Salt\",\n",
            "        \"Unsalted butter, softened\",\n",
            "        \"Granulated sugar\",\n",
            "        \"Packed brown sugar\",\n",
            "        \"Vanilla extract\",\n",
            "        \"Large eggs\",\n",
            "        \"Semi-sweet chocolate chips\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    ingredients: list[str]\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKai5CP_PGQF"
      },
      "source": [
        "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeyDWbnxO-on"
      },
      "outputs": [],
      "source": [
        "parsed_response: Recipe = response.parsed\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSLPrvlvXOc"
      },
      "source": [
        "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
        "\n",
        "- `enum`\n",
        "- `items`\n",
        "- `maxItems`\n",
        "- `nullable`\n",
        "- `properties`\n",
        "- `required`\n",
        "\n",
        "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7duWOq3vMmS"
      },
      "outputs": [],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"rating\": {\"type\": \"INTEGER\"},\n",
        "                \"flavor\": {\"type\": \"STRING\"},\n",
        "                \"sentiment\": {\n",
        "                    \"type\": \"STRING\",\n",
        "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
        "                },\n",
        "                \"explanation\": {\"type\": \"STRING\"},\n",
        "            },\n",
        "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
        "\n",
        "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
        "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema,\n",
        "    ),\n",
        ")\n",
        "\n",
        "response_dict = response.parsed\n",
        "print(response_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1dR-QlTKRs"
      },
      "source": [
        "## Count tokens and compute tokens\n",
        "\n",
        "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
        "\n",
        "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syx-fwLkV1j-"
      },
      "source": [
        "### Count tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhNElguLRRNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076cb89e-b608-46c9-a116-91aacfe32492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_tokens=9 cached_content_token_count=None\n"
          ]
        }
      ],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsP0vXOY7hg"
      },
      "source": [
        "## Search as a tool (Grounding)\n",
        "\n",
        "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you connect real-world data to the Gemini model.\n",
        "\n",
        "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
        "\n",
        "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n",
        "\n",
        "For more examples of Grounding, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_M_4RRBdO_3"
      },
      "source": [
        "### Google Search\n",
        "\n",
        "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
        "\n",
        "[Dynamic Retrieval](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#dynamic-retrieval) lets you set a threshold for when grounding is used for model responses. This is useful when the prompt doesn't require an answer grounded in Google Search and the supported models can provide an answer based on their knowledge without grounding. This helps you manage latency, quality, and cost more effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeR09J3AZT4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "ad10e808-d815-4778-f2a9-dd5893ebc165"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the search results, here is the current temperature information for Austin, TX as of Saturday, April 19, 2025:\n\nSeveral sources report slightly different temperatures, likely due to different specific locations within Austin and update times:\n\n*   One source indicates it is currently **74°F (23°C)**, feeling like 78°F (25°C), with cloudy conditions and 81% humidity.\n*   Another source (KVUE) shows hourly temperatures around **74°F** in the early morning hours (around 2-3 AM CDT).\n*   Weather Underground reports **78°F** from the Downtown station.\n*   AccuWeather reports **86°F** with mostly sunny conditions, feeling like 88°F. However, this seems unusually high for the early morning (around 2:37 AM CDT) and might reflect a daytime high or a delayed update.\n*   The National Weather Service (at Austin Camp Mabry) reported **91°F (33°C)** with partly cloudy conditions, feeling like 92°F, at 2:51 PM CDT on April 18th. This is likely outdated for the current time.\n*   FOX 7 Austin reported **91°F**, feeling like 92°F, as of 3:30 PM CDT (presumably on April 18th). This is also likely outdated for the current time.\n\nGiven the current time (around 2:37 AM CDT in Austin), the **74°F** reading seems most plausible for the current temperature. Conditions are generally reported as cloudy."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grounding_chunks=[GroundingChunk(retrieved_context=None, web=GroundingChunkWeb(domain='wunderground.com', title='wunderground.com', uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAKjXWM-q1tPnGxURvK_uEBJj6kxfzpA3PRbn1SGDTCXNd5QXpoSUgj9aQ__wzwCjXgcpnAQdjy4_rePbkreC28HyjjEBZHt0Tg-VGZGEk0YOVOVQLAdWssPN-i_O13WO1K43SdE0wIzy4J4geC7'))] grounding_supports=[GroundingSupport(confidence_scores=[0.7198736], grounding_chunk_indices=[0], segment=Segment(end_index=567, part_index=None, start_index=499, text='*   Weather Underground reports **78°F** from the Downtown station.'))] retrieval_metadata=RetrievalMetadata(google_search_dynamic_retrieval_score=None) retrieval_queries=None search_entry_point=SearchEntryPoint(rendered_content='<style>\\n.container {\\n  align-items: center;\\n  border-radius: 8px;\\n  display: flex;\\n  font-family: Google Sans, Roboto, sans-serif;\\n  font-size: 14px;\\n  line-height: 20px;\\n  padding: 8px 12px;\\n}\\n.chip {\\n  display: inline-block;\\n  border: solid 1px;\\n  border-radius: 16px;\\n  min-width: 14px;\\n  padding: 5px 16px;\\n  text-align: center;\\n  user-select: none;\\n  margin: 0 8px;\\n  -webkit-tap-highlight-color: transparent;\\n}\\n.carousel {\\n  overflow: auto;\\n  scrollbar-width: none;\\n  white-space: nowrap;\\n  margin-right: -12px;\\n}\\n.headline {\\n  display: flex;\\n  margin-right: 4px;\\n}\\n.gradient-container {\\n  position: relative;\\n}\\n.gradient {\\n  position: absolute;\\n  transform: translate(3px, -9px);\\n  height: 36px;\\n  width: 9px;\\n}\\n@media (prefers-color-scheme: light) {\\n  .container {\\n    background-color: #fafafa;\\n    box-shadow: 0 0 0 1px #0000000f;\\n  }\\n  .headline-label {\\n    color: #1f1f1f;\\n  }\\n  .chip {\\n    background-color: #ffffff;\\n    border-color: #d2d2d2;\\n    color: #5e5e5e;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:focus {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:active {\\n    background-color: #d8d8d8;\\n    border-color: #b6b6b6;\\n  }\\n  .logo-dark {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\\n  }\\n}\\n@media (prefers-color-scheme: dark) {\\n  .container {\\n    background-color: #1f1f1f;\\n    box-shadow: 0 0 0 1px #ffffff26;\\n  }\\n  .headline-label {\\n    color: #fff;\\n  }\\n  .chip {\\n    background-color: #2c2c2c;\\n    border-color: #3c4043;\\n    color: #fff;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #353536;\\n  }\\n  .chip:focus {\\n    background-color: #353536;\\n  }\\n  .chip:active {\\n    background-color: #464849;\\n    border-color: #53575b;\\n  }\\n  .logo-light {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\\n  }\\n}\\n</style>\\n<div class=\"container\">\\n  <div class=\"headline\">\\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\\n  </div>\\n  <div class=\"carousel\">\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqALJttTB1hs_INfD-Ep87G6Zq0NoedK7eqr8efxR9YhQD7ZfPis3pKAIdoREWPlW3I5GQxEcBV6imlpRB0DVlKsMKdibI61g0LNn82WN4qw-VIkAnU0OCpDF_wHIQ3ZArfimUJAUnhXlv5-FTc1UVlDWiHELqilr7qcFQaTXu4uqFHzjUDa5iEhnCD1u7lGi-9Tqeqhq26UhMQ==\">weather Austin TX now</a>\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAKN9c7tQrvFtnj-PQhECHC8W4jK1HQmJXEaMiGDWrtnX0Fho_JXtZGLbHFfseqgOdKYVbPYvpKFAtsxLVCAuPXDADynR4NUzd8Hg8mO9zLYe1hRYGa1cF3ka6-XUBwy8dFLK-KRp0S17kRozlEId-LeoOeWGkLlIvVY7s5JAHpl-jGPTVbEOGjJ9NIjrxm0c8uF-qO6D9HvI5JUKVGSiZfuEaFULpkQOzPWqI8Wqp_Yt33Ialu0Q4o=\">What is the current temperature in Austin, Texas?</a>\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAKDXxRYD4aiLKbXnzQfnTBkqTz14lkvxBBnkd2X4x74cIdIZLjmP4wgXT0WfekFJOV_X9CVj3-gBhecMuJQu1nsN2kIrNdx5P9scL0sug92X5H1xmD2M3B9YZqwzkV9y7cyl5yGoLXZ5f6NiljXxHqz-PZTaTGCWutwjTtXVePQ9Ny8w9puI6KIAFFAZWM0b5xej4OyhaCPJ8AnGJ_JvlgQ\">Austin TX current temperature</a>\\n  </div>\\n</div>\\n', sdk_blob=None) web_search_queries=['What is the current temperature in Austin, Texas?', 'Austin TX current temperature', 'weather Austin TX now']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqALJttTB1hs_INfD-Ep87G6Zq0NoedK7eqr8efxR9YhQD7ZfPis3pKAIdoREWPlW3I5GQxEcBV6imlpRB0DVlKsMKdibI61g0LNn82WN4qw-VIkAnU0OCpDF_wHIQ3ZArfimUJAUnhXlv5-FTc1UVlDWiHELqilr7qcFQaTXu4uqFHzjUDa5iEhnCD1u7lGi-9Tqeqhq26UhMQ==\">weather Austin TX now</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAKN9c7tQrvFtnj-PQhECHC8W4jK1HQmJXEaMiGDWrtnX0Fho_JXtZGLbHFfseqgOdKYVbPYvpKFAtsxLVCAuPXDADynR4NUzd8Hg8mO9zLYe1hRYGa1cF3ka6-XUBwy8dFLK-KRp0S17kRozlEId-LeoOeWGkLlIvVY7s5JAHpl-jGPTVbEOGjJ9NIjrxm0c8uF-qO6D9HvI5JUKVGSiZfuEaFULpkQOzPWqI8Wqp_Yt33Ialu0Q4o=\">What is the current temperature in Austin, Texas?</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAKDXxRYD4aiLKbXnzQfnTBkqTz14lkvxBBnkd2X4x74cIdIZLjmP4wgXT0WfekFJOV_X9CVj3-gBhecMuJQu1nsN2kIrNdx5P9scL0sug92X5H1xmD2M3B9YZqwzkV9y7cyl5yGoLXZ5f6NiljXxHqz-PZTaTGCWutwjTtXVePQ9Ny8w9puI6KIAFFAZWM0b5xej4OyhaCPJ8AnGJ_JvlgQ\">Austin TX current temperature</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "google_search_tool = Tool(google_search=GoogleSearch())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the current temperature in Austin, TX?\",\n",
        "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "\n",
        "print(response.candidates[0].grounding_metadata)\n",
        "\n",
        "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0pb-Kh1xEHU"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
        "\n",
        "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
        "\n",
        "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "For more examples of Function calling with Gemini, check out this notebook: [Intro to Function Calling with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSUWWlrrlR-D"
      },
      "source": [
        "### Python Function (Automatic Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRR8HZhLlR-E"
      },
      "outputs": [],
      "source": [
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Example method. Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA\n",
        "    \"\"\"\n",
        "    weather_map: dict[str, str] = {\n",
        "        \"Boston, MA\": \"snowing\",\n",
        "        \"San Francisco, CA\": \"foggy\",\n",
        "        \"Seattle, WA\": \"raining\",\n",
        "        \"Austin, TX\": \"hot\",\n",
        "        \"Chicago, IL\": \"windy\",\n",
        "    }\n",
        "    return weather_map.get(location, \"unknown\")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the weather like in San Francisco?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4syyLEClGcn"
      },
      "source": [
        "### OpenAPI Specification (Manual Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BDQPwgcxRN3"
      },
      "outputs": [],
      "source": [
        "get_destination = FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.function_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDs2X3o0neK"
      },
      "source": [
        "## Code Execution\n",
        "\n",
        "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
        "\n",
        "The Gemini API provides code execution as a tool, similar to function calling.\n",
        "After you add code execution as a tool, the model decides when to use it.\n",
        "\n",
        "For more examples of Code Execution, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/code-execution/intro_code_execution.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W-3c7sy0nyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "e9230e8c-295e-4b7d-8a6e-3fae77350f10"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Code\n\n```py\nimport sys\n# Increase recursion depth limit for potential recursive approaches, though iteration is preferred\n# sys.setrecursionlimit(2000)\n\ndef fibonacci(n):\n    if n < 0:\n        raise ValueError(\"Input should be a non-negative integer.\")\n    elif n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        a, b = 0, 1\n        for _ in range(2, n + 1):\n            a, b = b, a + b\n        return b\n\n# Calculate the 20th Fibonacci number (index 20, assuming F_0=0, F_1=1)\nn_term = 20\nfib_20 = fibonacci(n_term)\n\nprint(f'{n_term=}')\nprint(f'{fib_20=}')\n\n```\n\n### Output\n\n```\nn_term=20\nfib_20=6765\n\n```\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[code_execution_tool],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "## Code\n",
        "\n",
        "```py\n",
        "{response.executable_code}\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "{response.code_execution_result}\n",
        "```\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b5adb2eb70"
      },
      "source": [
        "## Thinking mode examples\n",
        "\n",
        "The following examples are some complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n",
        "### **Example 1**: Code generation\n",
        "\n",
        "Gemini 2.5 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing.\n",
        "\n",
        "Let's see how the model uses its reasoning capabilities to create a video game, using executable code from a single line prompt. See the example game [here](https://www.youtube.com/watch?v=RLCBSpgos6s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f120dff0d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2e7770d-0bfd-46cf-daa4-fa0d9e39c079"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here is a captivating pixelated dinosaur endless runner game using p5.js, with on-screen instructions and interesting layered backgrounds. Everything is contained within the p5.js sketch.\n\n```javascript\n// --- Game Configuration ---\nlet dino;\nlet obstacles = [];\nlet score = 0;\nlet hiScore = 0;\nlet gameState = 'START'; // START, PLAYING, GAME_OVER\nlet gameSpeed;\nlet initialGameSpeed = 6;\nlet speedIncreaseFactor = 0.001;\nlet obstacleSpawnRate = 90; // Lower number = more frequent spawns (frames)\nlet lastObstacleFrame = 0;\n\n// --- Background Configuration ---\nlet groundLevel;\nlet skyColor;\nlet groundColor;\nlet layer1Color; // Far hills\nlet layer2Color; // Closer hills/features\nlet layer1Pos = 0;\nlet layer2Pos = 0;\nlet groundPos = 0;\nlet layer1SpeedFactor = 0.1;\nlet layer2SpeedFactor = 0.3;\nlet groundSpeedFactor = 1.0;\n\n// --- Dino Configuration ---\nconst DINO_WIDTH = 40;\nconst DINO_HEIGHT = 50;\nconst DINO_COLOR = [80, 180, 80]; // Greenish\nconst DINO_EYE_COLOR = [255]; // White\nconst DINO_GRAVITY = 0.6;\nconst DINO_JUMP_FORCE = -12;\nconst DINO_GROUND_OFFSET = 10; // How far above the absolute ground line\n\n// --- Obstacle Configuration ---\nconst OBSTACLE_MIN_WIDTH = 20;\nconst OBSTACLE_MAX_WIDTH = 40;\nconst OBSTACLE_MIN_HEIGHT = 30;\nconst OBSTACLE_MAX_HEIGHT = 60;\nconst OBSTACLE_COLOR = [200, 80, 80]; // Reddish\n\n// --- Font ---\nlet pixelFont; // Will load default font but structure is here if you add one\n\nfunction preload() {\n  // pixelFont = loadFont('path/to/your/pixel-font.ttf'); // Optional: Load a pixel font\n}\n\nfunction setup() {\n  createCanvas(windowWidth, windowHeight);\n  //textFont(pixelFont || 'monospace'); // Use loaded font or fallback\n  textFont('monospace');\n  textAlign(CENTER, CENTER);\n  rectMode(CORNER); // Use CORNER mode for most drawing\n\n  groundLevel = height * 0.8;\n  skyColor = color(135, 206, 250); // Light Sky Blue\n  groundColor = color(139, 69, 19); // Saddle Brown\n  layer1Color = color(34, 139, 34, 150); // Forest Green (semi-transparent)\n  layer2Color = color(0, 100, 0, 200);  // Dark Green (more opaque)\n\n  resetGame();\n}\n\nfunction draw() {\n  // --- Background ---\n  drawBackground();\n\n  // --- Game State Logic ---\n  switch (gameState) {\n    case 'START':\n      drawStartScreen();\n      break;\n    case 'PLAYING':\n      updateGame();\n      drawGame();\n      break;\n    case 'GAME_OVER':\n      drawGameOverScreen();\n      break;\n  }\n\n   // --- Draw UI (Score) ---\n   drawScore();\n}\n\n// ==============================\n// === Game State Functions ===\n// ==============================\n\nfunction updateGame() {\n  // Increase game speed gradually\n  gameSpeed += speedIncreaseFactor;\n\n  // Update Dino\n  dino.update();\n\n  // Update and spawn obstacles\n  handleObstacles();\n\n  // Check for collisions\n  checkCollisions();\n\n  // Increment score\n  score++;\n}\n\nfunction drawGame() {\n  // Draw Obstacles\n  for (let obs of obstacles) {\n    obs.show();\n  }\n\n  // Draw Dino\n  dino.show();\n\n  // Draw Ground Line (redundant if background handles it, but ensures alignment)\n  stroke(groundColor);\n  strokeWeight(2);\n  line(0, groundLevel, width, groundLevel);\n  noStroke();\n}\n\nfunction drawStartScreen() {\n  fill(0, 0, 0, 150); // Semi-transparent overlay\n  rect(0, 0, width, height);\n\n  fill(255);\n  textSize(48);\n  text(\"Pixel Dino Runner\", width / 2, height / 3);\n\n  textSize(24);\n  text(\"Press SPACE or Click to Jump\", width / 2, height / 2);\n  text(\"Avoid the Obstacles!\", width / 2, height / 2 + 40);\n  text(\"Press SPACE or Click to Start\", width / 2, height / 2 + 100);\n}\n\nfunction drawGameOverScreen() {\n   // Draw obstacles & dino in their final state\n   drawGame();\n\n   // Overlay\n  fill(0, 0, 0, 180);\n  rect(0, 0, width, height);\n\n  fill(255, 0, 0); // Red for Game Over\n  textSize(64);\n  text(\"GAME OVER\", width / 2, height / 3);\n\n  fill(255); // White for score\n  textSize(32);\n  text(`Score: ${score}`, width / 2, height / 2);\n  text(`High Score: ${hiScore}`, width / 2, height / 2 + 50);\n\n  textSize(24);\n  text(\"Press 'R' or Click to Restart\", width / 2, height / 2 + 120);\n}\n\nfunction drawScore() {\n    fill(255);\n    stroke(0); // Black outline for readability\n    strokeWeight(2);\n    textSize(24);\n    textAlign(LEFT, TOP);\n    text(`Score: ${score}`, 20, 20);\n    text(`Hi: ${hiScore}`, 20, 50);\n    textAlign(CENTER, CENTER); // Reset alignment\n    noStroke();\n}\n\n\n// ==============================\n// === Background Drawing ===\n// ==============================\n\nfunction drawBackground() {\n    // Sky\n    background(skyColor);\n\n    // Update positions (only if playing)\n    if (gameState === 'PLAYING') {\n        layer1Pos -= gameSpeed * layer1SpeedFactor;\n        layer2Pos -= gameSpeed * layer2SpeedFactor;\n        groundPos -= gameSpeed * groundSpeedFactor;\n    }\n\n    // Reset positions when they scroll off-screen\n    if (layer1Pos < -width) layer1Pos += width;\n    if (layer2Pos < -width) layer2Pos += width;\n    if (groundPos < -width) groundPos += width;\n\n\n    // Draw Layer 1 (Far Hills) - Simple shapes\n    fill(layer1Color);\n    noStroke();\n    // Draw two copies side-by-side for seamless looping\n    drawHillLayer(layer1Pos, groundLevel - 50, 80, 100, 5); // x, y, baseY, variationY, numHills\n    drawHillLayer(layer1Pos + width, groundLevel - 50, 80, 100, 5);\n\n    // Draw Layer 2 (Closer features) - More detailed shapes\n    fill(layer2Color);\n    noStroke();\n    drawFeatureLayer(layer2Pos, groundLevel - 20, 40, 60, 8); // x, y, baseY, variationY, numFeatures\n    drawFeatureLayer(layer2Pos + width, groundLevel - 20, 40, 60, 8);\n\n\n    // Draw Ground\n    fill(groundColor);\n    noStroke();\n    rect(0, groundLevel, width, height - groundLevel);\n\n    // Optional: Add some ground texture/details (repeating pattern)\n    fill(118, 60, 14); // Darker brown details\n    let detailSize = 10;\n    let numDetails = floor(width / (detailSize * 3));\n     for (let i = 0; i < numDetails * 2; i++) { // Draw double for looping\n        let detailX = groundPos + i * detailSize * 3 + random(-5, 5);\n        let detailY = groundLevel + random(5, height - groundLevel - 5);\n        rect(detailX % (width*2) - width, detailY, detailSize, detailSize / 2); // Use modulo for wrapping\n    }\n}\n\n// Helper to draw a layer of hills\nfunction drawHillLayer(startX, baseY, minHeight, maxHeight, numHills) {\n    let hillWidth = width / numHills;\n    for (let i = 0; i < numHills; i++) {\n        let hillHeight = random(minHeight, maxHeight);\n        let hillX = startX + i * hillWidth;\n        let hillY = baseY - hillHeight;\n        // Simple triangle or rounded rect for hills\n        // rect(hillX, hillY, hillWidth, hillHeight, 10); // Rounded rect\n         beginShape();\n         vertex(hillX, baseY);\n         vertex(hillX + hillWidth / 2, hillY);\n         vertex(hillX + hillWidth, baseY);\n         endShape(CLOSE);\n    }\n}\n\n// Helper to draw a layer of features (like bushes/rocks)\nfunction drawFeatureLayer(startX, baseY, minSize, maxSize, numFeatures) {\n    let featureSpacing = width / numFeatures;\n    for (let i = 0; i < numFeatures; i++) {\n        let featureSize = random(minSize, maxSize);\n        let featureX = startX + i * featureSpacing + random(-featureSpacing/4, featureSpacing/4);\n        let featureY = baseY - featureSize / 2 + random(-10, 10); // Add Y variation\n        // Simple ellipse or rect\n        ellipse(featureX + featureSize/2, featureY + featureSize/2, featureSize * 1.2, featureSize);\n        // rect(featureX, featureY, featureSize, featureSize / 2);\n    }\n}\n\n\n// ==============================\n// === Game Mechanics ===\n// ==============================\n\nfunction handleObstacles() {\n  // Spawn new obstacles periodically\n  if (frameCount - lastObstacleFrame > obstacleSpawnRate) {\n    // Add some randomness to spawn timing\n     if (random(1) < 0.6) { // Chance to spawn\n        obstacles.push(new Obstacle());\n        lastObstacleFrame = frameCount;\n\n        // Slightly decrease spawn rate over time to increase difficulty\n        if(obstacleSpawnRate > 40) { // Don't let it get too fast\n           obstacleSpawnRate *= 0.995;\n        }\n     } else {\n        // Still update last frame even if we didn't spawn, prevents clumping after a pause\n         lastObstacleFrame = frameCount;\n     }\n  }\n\n  // Update and remove off-screen obstacles\n  for (let i = obstacles.length - 1; i >= 0; i--) {\n    obstacles[i].update();\n    if (obstacles[i].isOffscreen()) {\n      obstacles.splice(i, 1);\n    }\n  }\n}\n\nfunction checkCollisions() {\n  for (let obs of obstacles) {\n    if (dino.collidesWith(obs)) {\n      gameOver();\n      break; // No need to check further\n    }\n  }\n}\n\nfunction resetGame() {\n  dino = new Dino();\n  obstacles = [];\n  score = 0;\n  gameSpeed = initialGameSpeed;\n  obstacleSpawnRate = 90;\n  lastObstacleFrame = frameCount; // Reset spawn timer\n  layer1Pos = 0; // Reset background positions\n  layer2Pos = 0;\n  groundPos = 0;\n  // Keep gameState as is, it will be changed by input\n}\n\nfunction gameOver() {\n  if (score > hiScore) {\n    hiScore = score;\n  }\n  gameState = 'GAME_OVER';\n  // Optional: Add screen shake or sound effect here\n}\n\n// ==============================\n// === Input Handling ===\n// ==============================\n\nfunction keyPressed() {\n  if (keyCode === 32) { // SPACE bar\n    handleJumpInput();\n  } else if ((key === 'r' || key === 'R') && gameState === 'GAME_OVER') {\n     handleRestartInput();\n  }\n  return false; // Prevent default browser behavior (scrolling)\n}\n\nfunction mousePressed() {\n    handleJumpInput();\n    if (gameState === 'GAME_OVER'){\n        handleRestartInput();\n    }\n     return false; // Prevent default browser behavior\n}\n\nfunction handleJumpInput(){\n     if (gameState === 'START') {\n      gameState = 'PLAYING';\n    } else if (gameState === 'PLAYING') {\n      dino.jump();\n    }\n}\n\nfunction handleRestartInput(){\n     if (gameState === 'GAME_OVER') {\n        resetGame();\n        gameState = 'START'; // Go back to start screen\n        // or gameState = 'PLAYING'; // to jump right back in\n    }\n}\n\n\n// ==============================\n// === Classes ===\n// ==============================\n\nclass Dino {\n  constructor() {\n    this.w = DINO_WIDTH;\n    this.h = DINO_HEIGHT;\n    this.x = this.w * 2; // Start position\n    this.y = groundLevel - this.h - DINO_GROUND_OFFSET;\n    this.baseY = this.y; // To check if on ground\n    this.velocityY = 0;\n    this.gravity = DINO_GRAVITY;\n    this.jumpForce = DINO_JUMP_FORCE;\n    this.onGround = true;\n  }\n\n  jump() {\n    // Only jump if on the ground\n    if (this.onGround) {\n      this.velocityY = this.jumpForce;\n      this.onGround = false;\n    }\n  }\n\n  update() {\n    // Apply gravity\n    this.velocityY += this.gravity;\n    this.y += this.velocityY;\n\n    // Check for ground collision\n    let dinoGround = groundLevel - this.h - DINO_GROUND_OFFSET;\n    if (this.y >= dinoGround) {\n      this.y = dinoGround;\n      this.velocityY = 0;\n      this.onGround = true;\n    } else {\n        this.onGround = false; // Make sure it's false if in the air\n    }\n  }\n\n  show() {\n    push(); // Isolate drawing state\n    translate(this.x, this.y);\n    noStroke();\n\n    // --- Simple Pixel Dino Body ---\n    let blockSize = 5; // Size of our 'pixels'\n\n    // Torso (adjust block positions relative to 0,0)\n    fill(DINO_COLOR);\n    for(let i=0; i<5; i++) rect(blockSize*2, blockSize*i, blockSize*4, blockSize); // Main body column\n    rect(blockSize, blockSize*3, blockSize, blockSize); // Neck base\n    rect(blockSize*6, blockSize*1, blockSize, blockSize*3); // Tail base\n\n    // Head\n    rect(0, blockSize*2, blockSize*2, blockSize*2); // Head main\n    rect(blockSize, blockSize, blockSize, blockSize); // Top of head\n\n    // Tail\n    rect(blockSize*7, blockSize, blockSize, blockSize*2);\n    rect(blockSize*8, blockSize, blockSize, blockSize);\n\n    // Legs (simple alternating look if needed, but static for now)\n     // Legs are tricky without animation, let's do static stubby ones\n    rect(blockSize * 3, blockSize * 5, blockSize, blockSize*2);\n    rect(blockSize * 5, blockSize * 5, blockSize, blockSize*2);\n\n\n    // Eye\n    fill(DINO_EYE_COLOR);\n    rect(blockSize, blockSize*2, blockSize, blockSize); // Simple eye\n\n    pop(); // Restore drawing state\n  }\n\n  collidesWith(obstacle) {\n    // Simple Axis-Aligned Bounding Box (AABB) collision detection\n    // Get dino's bounding box\n    let dLeft = this.x;\n    let dRight = this.x + this.w;\n    let dTop = this.y;\n    let dBottom = this.y + this.h;\n\n    // Get obstacle's bounding box\n    let oLeft = obstacle.x;\n    let oRight = obstacle.x + obstacle.w;\n    let oTop = obstacle.y;\n    let oBottom = obstacle.y + obstacle.h;\n\n    // Check for overlap\n    return (\n      dRight > oLeft &&\n      dLeft < oRight &&\n      dBottom > oTop &&\n      dTop < oBottom\n    );\n  }\n}\n\nclass Obstacle {\n  constructor() {\n    this.w = random(OBSTACLE_MIN_WIDTH, OBSTACLE_MAX_WIDTH);\n    this.h = random(OBSTACLE_MIN_HEIGHT, OBSTACLE_MAX_HEIGHT);\n    this.x = width; // Start off-screen right\n    this.y = groundLevel - this.h; // Align with ground\n    this.speed = gameSpeed; // Use the current global game speed\n  }\n\n  update() {\n    this.x -= this.speed; // Move left\n    // Update speed in case global gameSpeed changed since creation\n    this.speed = gameSpeed;\n  }\n\n  show() {\n     push();\n     translate(this.x, this.y);\n     fill(OBSTACLE_COLOR);\n     noStroke();\n    // --- Simple Pixel Obstacle (Cactus-like) ---\n    let blockSize = 5;\n    let coreWidthBlocks = floor(this.w / blockSize / 1.5);\n    let coreHeightBlocks = floor(this.h / blockSize);\n    let coreXOffset = floor((this.w - coreWidthBlocks * blockSize) / 2); // Center it roughly\n\n    // Main stem\n    rect(coreXOffset, 0, coreWidthBlocks * blockSize, coreHeightBlocks * blockSize);\n\n    // Random arms (optional, adds variation)\n    if (this.h > OBSTACLE_MIN_HEIGHT * 1.5 && this.w > OBSTACLE_MIN_WIDTH * 1.2) { // Only on bigger ones\n        let armHeightBlocks = floor(coreHeightBlocks * 0.5);\n        let armY = floor(coreHeightBlocks * 0.2) * blockSize;\n        // Left arm\n        if(random() > 0.4){\n             rect(coreXOffset - blockSize*2, armY, blockSize*2, armHeightBlocks * blockSize);\n             rect(coreXOffset - blockSize*3, armY + blockSize, blockSize, (armHeightBlocks-1) * blockSize); // Tip\n        }\n        // Right arm\n         if(random() > 0.4){\n             rect(coreXOffset + coreWidthBlocks * blockSize, armY, blockSize*2, armHeightBlocks * blockSize);\n             rect(coreXOffset + (coreWidthBlocks+2) * blockSize, armY + blockSize, blockSize, (armHeightBlocks-1) * blockSize); // Tip\n         }\n    }\n\n     pop();\n  }\n\n  isOffscreen() {\n    return this.x + this.w < 0;\n  }\n}\n\n// Make canvas responsive\nfunction windowResized() {\n  resizeCanvas(windowWidth, windowHeight);\n  // Recalculate positions based on new height, etc.\n  groundLevel = height * 0.8;\n  // We might need to reposition the dino if it was in the air during resize\n  if(dino){\n      let dinoGround = groundLevel - dino.h - DINO_GROUND_OFFSET;\n       if (dino.y > dinoGround) { // If resize pushed dino below ground\n          dino.y = dinoGround;\n          dino.onGround = true;\n       }\n  }\n\n  // Reset background positions on resize? Maybe not, let them continue.\n}\n\n\n```\n\n**How to Use:**\n\n1.  **p5.js Editor:** Go to the p5.js online editor ([editor.p5js.org](https://editor.p5js.org/)).\n2.  **Paste Code:** Delete the default `setup` and `draw` functions in the editor and paste this entire code block.\n3.  **Run:** Press the \"Play\" button (the triangle).\n\n**Game Instructions (On-Screen):**\n\n*   **Start:** The game begins on a start screen. Press the `SPACE` bar or `Click` the mouse to begin playing.\n*   **Play:** Press `SPACE` or `Click` to make the dinosaur jump over the red obstacles.\n*   **Game Over:** If you hit an obstacle, the game ends. Your score and high score are displayed. Press `R` or `Click` to return to the start screen.\n\n**Features:**\n\n1.  **Pixelated Dino:** A simple dinosaur drawn using `rect()` blocks for a pixelated feel.\n2.  **Pixelated Obstacles:** Cactus-like obstacles also drawn with blocks.\n3.  **Endless Scrolling:** The game continues indefinitely until you collide.\n4.  **Increasing Difficulty:** The game speed slowly increases over time, and obstacles might spawn slightly faster.\n5.  **Parallax Background:** Multiple background layers (sky, far hills, closer features, ground details) scroll at different speeds, creating a sense of depth. The background elements are procedurally drawn shapes.\n6.  **Scoring:** Score increases as you survive. High score is tracked.\n7.  **Game States:** Clear `START`, `PLAYING`, and `GAME_OVER` states.\n8.  **On-Screen Instructions:** Text prompts guide the player.\n9.  **Responsive Canvas:** Adjusts to the browser window size.\n10. **Input:** Works with both `SPACE` bar and mouse clicks for jumping and restarting.\n\nEnjoy your pixelated dino run!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "  Make me a captivating endless runner game. Key instructions on the screen. p5js scene, no HTML.\n",
        "  I like pixelated dinosaurs and interesting backgrounds.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecf22b47bdc3"
      },
      "source": [
        "### **Example 2**: Multimodal reasoning (Geometry)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using multimodal capabilities to reason across text and image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60260c0ac118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4a85746c-d72d-480c-f644-21d478022f1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = (\n",
        "    \"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\"\n",
        ")\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c972334f62ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "b30d3ba1-6af5-4150-ffa2-fafc694b662b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "*   **Identify the shapes:** We have a circle and a right-angled triangle.\n*   **Identify the circle's properties:** Several radii are shown and labeled with length 3. Therefore, the radius of the circle (r) is 3. The center of the circle is where these radii meet.\n*   **Identify the triangle's properties:** The triangle has two sides originating from the circle's center labeled with length 3. These sides form a right angle at the circle's center. So, it's a right-angled triangle with legs of length 3.\n*   **Identify the overlapping region:** The region where the circle and triangle overlap is the part of the circle that lies within the triangle. This overlapping region forms a sector of the circle.\n*   **Determine the sector's properties:**\n    *   The sector's radius is the circle's radius, r = 3.\n    *   The sector's central angle is the angle of the triangle at the circle's center, which is 90 degrees (or π/2 radians).\n*   **Calculate the area of the sector:** The area of a sector is a fraction of the total circle's area, determined by the central angle.\n    *   Total area of the circle = π * r² = π * (3)² = 9π.\n    *   The fraction of the circle represented by the sector = (Central Angle) / (Total Angle in a Circle) = 90° / 360° = 1/4.\n    *   Area of the overlapping sector = (1/4) * (Total area of the circle) = (1/4) * 9π = 9π/4.\n\nThe area of the overlapping region is **9π/4**."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"What's the area of the overlapping region?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52656e92cd69"
      },
      "source": [
        "### **Example 3**:  Math and problem solving\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the thoughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d46387bdc9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "a89980ab-1b04-45e5-ad6e-b852fd789e56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/pool.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = \"https://storage.googleapis.com/generativeai-downloads/images/pool.png\"\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46b694793eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4f87c056-38ff-489b-9791-4e4d3e1e68cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This is a classic riddle! Here's how you solve it:\n\nMathematically, adding three odd numbers (7, 9, 11, 13) will always result in an odd number. Since 30 is an even number, you can't get 30 by simply adding three of these numbers together.\n\nThe trick is to think outside the box (or off the felt!):\n\n*   **Turn the 9 ball upside down to make it a 6.**\n*   Then, add: **6 + 11 + 13 = 30**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"How do I use three of the pool balls to sum up to 30?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwiONFdVHw5"
      },
      "source": [
        "## What's next\n",
        "\n",
        "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
        "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
        "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hIJVEr0RQY8S",
        "rZV2TY5Pa3Dd",
        "hYKAzG1sH-K1",
        "mSUWWlrrlR-D",
        "h4syyLEClGcn"
      ],
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}